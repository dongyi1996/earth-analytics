{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_BIYJwqBopmN"
   },
   "source": [
    "# Modeling\n",
    "1. [ElasticNet for yield prediction based on growing season weather](#section1)\n",
    "2. [RNN time-series for predict growing seasonal weather](#section2)\n",
    "3. [2020 National Corn Yield Prediction](#section3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "wdEUZYg3WTGp",
    "outputId": "78f5527e-5204-4aa9-e8bc-2e0b27dd132d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11695, 26)\n",
      "(34071, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CRD</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Area</th>\n",
       "      <th>Yield</th>\n",
       "      <th>Total_yield</th>\n",
       "      <th>Mn</th>\n",
       "      <th>State_code</th>\n",
       "      <th>ppt_m</th>\n",
       "      <th>ppt_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>tmean_median</th>\n",
       "      <th>tdif_m</th>\n",
       "      <th>tdif_median</th>\n",
       "      <th>tdif_max</th>\n",
       "      <th>tdif_min</th>\n",
       "      <th>RDI</th>\n",
       "      <th>SPI</th>\n",
       "      <th>PET</th>\n",
       "      <th>SPEI</th>\n",
       "      <th>PNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>2063600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092186</td>\n",
       "      <td>2.581206</td>\n",
       "      <td>...</td>\n",
       "      <td>64.878159</td>\n",
       "      <td>27.438870</td>\n",
       "      <td>28.873679</td>\n",
       "      <td>35.984079</td>\n",
       "      <td>11.641867</td>\n",
       "      <td>-1.469619</td>\n",
       "      <td>-0.743303</td>\n",
       "      <td>67.829868</td>\n",
       "      <td>-0.212651</td>\n",
       "      <td>0.907934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>2063600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.218002</td>\n",
       "      <td>5.886043</td>\n",
       "      <td>...</td>\n",
       "      <td>75.750555</td>\n",
       "      <td>21.400068</td>\n",
       "      <td>21.550048</td>\n",
       "      <td>28.771781</td>\n",
       "      <td>11.868437</td>\n",
       "      <td>-1.182696</td>\n",
       "      <td>-0.482563</td>\n",
       "      <td>125.774297</td>\n",
       "      <td>-0.265521</td>\n",
       "      <td>0.922967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>2063600.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127955</td>\n",
       "      <td>3.454786</td>\n",
       "      <td>...</td>\n",
       "      <td>82.427654</td>\n",
       "      <td>21.406183</td>\n",
       "      <td>21.553994</td>\n",
       "      <td>25.942136</td>\n",
       "      <td>16.029412</td>\n",
       "      <td>-1.151546</td>\n",
       "      <td>-0.166277</td>\n",
       "      <td>173.622551</td>\n",
       "      <td>-0.279187</td>\n",
       "      <td>0.959448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>2063600.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.122960</td>\n",
       "      <td>3.442891</td>\n",
       "      <td>...</td>\n",
       "      <td>84.433309</td>\n",
       "      <td>20.639627</td>\n",
       "      <td>20.681452</td>\n",
       "      <td>24.000302</td>\n",
       "      <td>16.696620</td>\n",
       "      <td>-1.183056</td>\n",
       "      <td>-0.440580</td>\n",
       "      <td>190.856206</td>\n",
       "      <td>-0.765192</td>\n",
       "      <td>0.913384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>2063600.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118825</td>\n",
       "      <td>3.208287</td>\n",
       "      <td>...</td>\n",
       "      <td>83.826763</td>\n",
       "      <td>20.127898</td>\n",
       "      <td>20.974091</td>\n",
       "      <td>25.554035</td>\n",
       "      <td>11.240143</td>\n",
       "      <td>-1.114317</td>\n",
       "      <td>0.127317</td>\n",
       "      <td>177.288993</td>\n",
       "      <td>-0.580387</td>\n",
       "      <td>1.012049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  CRD  FIPS     Area  Yield  Total_yield  Mn  State_code     ppt_m  \\\n",
       "0  2010   40   140  22000.0   93.8    2063600.0   4           1  0.092186   \n",
       "1  2010   40   140  22000.0   93.8    2063600.0   5           1  0.218002   \n",
       "2  2010   40   140  22000.0   93.8    2063600.0   6           1  0.127955   \n",
       "3  2010   40   140  22000.0   93.8    2063600.0   7           1  0.122960   \n",
       "4  2010   40   140  22000.0   93.8    2063600.0   8           1  0.118825   \n",
       "\n",
       "    ppt_sum  ...  tmean_median     tdif_m  tdif_median   tdif_max   tdif_min  \\\n",
       "0  2.581206  ...     64.878159  27.438870    28.873679  35.984079  11.641867   \n",
       "1  5.886043  ...     75.750555  21.400068    21.550048  28.771781  11.868437   \n",
       "2  3.454786  ...     82.427654  21.406183    21.553994  25.942136  16.029412   \n",
       "3  3.442891  ...     84.433309  20.639627    20.681452  24.000302  16.696620   \n",
       "4  3.208287  ...     83.826763  20.127898    20.974091  25.554035  11.240143   \n",
       "\n",
       "        RDI       SPI         PET      SPEI       PNP  \n",
       "0 -1.469619 -0.743303   67.829868 -0.212651  0.907934  \n",
       "1 -1.182696 -0.482563  125.774297 -0.265521  0.922967  \n",
       "2 -1.151546 -0.166277  173.622551 -0.279187  0.959448  \n",
       "3 -1.183056 -0.440580  190.856206 -0.765192  0.913384  \n",
       "4 -1.114317  0.127317  177.288993 -0.580387  1.012049  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load data with known FIPS-level yield (some missing) at growing season\n",
    "df_gs = pd.read_csv('data/weather_g_season.csv')\n",
    "df_gs.fillna(0, inplace=True)\n",
    "print(df_gs.shape)\n",
    "# load target data with \n",
    "target_df = pd.read_csv('data/national_yld_cln.csv')\n",
    "# load data with all season weather data as well as indices\n",
    "df_pred = pd.read_csv('data/weather_all_season.csv')\n",
    "df_pred.fillna(0, inplace=True)\n",
    "print(df_pred.shape)\n",
    "\n",
    "df_gs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cpc6T6a1XBmg"
   },
   "source": [
    "<a id='section1'></a>\n",
    "## Fit an ElasticNet Model Based on Growing Season\n",
    "* pivot table from long to wide\n",
    "* fit elasticnet model with 5-fold crossVal\n",
    "* predict on national level yield and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "GTvwFrpPW6T1",
    "outputId": "7f5508f9-666c-43e2-eec7-8736cd397c14"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>CRD</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Area</th>\n",
       "      <th>Yield</th>\n",
       "      <th>Total_yield</th>\n",
       "      <th>State_code</th>\n",
       "      <th colspan=\"3\" halign=\"left\">PET</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tmean_median</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tmin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>127000.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>16764000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>65.543294</td>\n",
       "      <td>111.491847</td>\n",
       "      <td>158.227597</td>\n",
       "      <td>...</td>\n",
       "      <td>63.895154</td>\n",
       "      <td>72.600094</td>\n",
       "      <td>80.407162</td>\n",
       "      <td>81.836860</td>\n",
       "      <td>82.698121</td>\n",
       "      <td>37.943095</td>\n",
       "      <td>46.667919</td>\n",
       "      <td>60.173894</td>\n",
       "      <td>61.110230</td>\n",
       "      <td>62.857805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>1310</td>\n",
       "      <td>13800.0</td>\n",
       "      <td>113.4</td>\n",
       "      <td>1564920.0</td>\n",
       "      <td>13</td>\n",
       "      <td>68.560757</td>\n",
       "      <td>117.693103</td>\n",
       "      <td>164.507182</td>\n",
       "      <td>...</td>\n",
       "      <td>64.004156</td>\n",
       "      <td>72.494026</td>\n",
       "      <td>80.247550</td>\n",
       "      <td>81.856725</td>\n",
       "      <td>81.734689</td>\n",
       "      <td>37.831221</td>\n",
       "      <td>44.635106</td>\n",
       "      <td>61.073172</td>\n",
       "      <td>61.285739</td>\n",
       "      <td>61.391250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>1710</td>\n",
       "      <td>2111000.0</td>\n",
       "      <td>170.1</td>\n",
       "      <td>359081100.0</td>\n",
       "      <td>17</td>\n",
       "      <td>61.216560</td>\n",
       "      <td>93.449041</td>\n",
       "      <td>133.389533</td>\n",
       "      <td>...</td>\n",
       "      <td>54.400199</td>\n",
       "      <td>59.898352</td>\n",
       "      <td>71.408736</td>\n",
       "      <td>75.561266</td>\n",
       "      <td>74.875042</td>\n",
       "      <td>29.558627</td>\n",
       "      <td>34.148131</td>\n",
       "      <td>54.359674</td>\n",
       "      <td>55.136327</td>\n",
       "      <td>51.756197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>1810</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>164.5</td>\n",
       "      <td>164500000.0</td>\n",
       "      <td>18</td>\n",
       "      <td>61.680076</td>\n",
       "      <td>93.111855</td>\n",
       "      <td>134.616544</td>\n",
       "      <td>...</td>\n",
       "      <td>55.329140</td>\n",
       "      <td>60.157302</td>\n",
       "      <td>73.427448</td>\n",
       "      <td>75.252502</td>\n",
       "      <td>74.974569</td>\n",
       "      <td>30.496707</td>\n",
       "      <td>35.351764</td>\n",
       "      <td>49.610917</td>\n",
       "      <td>53.269561</td>\n",
       "      <td>51.926810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>1910</td>\n",
       "      <td>1980000.0</td>\n",
       "      <td>184.7</td>\n",
       "      <td>365706000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>59.747472</td>\n",
       "      <td>85.280898</td>\n",
       "      <td>126.621425</td>\n",
       "      <td>...</td>\n",
       "      <td>54.598207</td>\n",
       "      <td>60.211175</td>\n",
       "      <td>69.662564</td>\n",
       "      <td>73.348930</td>\n",
       "      <td>74.895144</td>\n",
       "      <td>28.346277</td>\n",
       "      <td>30.802152</td>\n",
       "      <td>49.005702</td>\n",
       "      <td>59.023717</td>\n",
       "      <td>52.240249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year CRD  FIPS       Area  Yield  Total_yield State_code        PET  \\\n",
       "Mn                                                                    4   \n",
       "0   2010  10   110   127000.0  132.0   16764000.0          1  65.543294   \n",
       "1   2010  10  1310    13800.0  113.4    1564920.0         13  68.560757   \n",
       "2   2010  10  1710  2111000.0  170.1  359081100.0         17  61.216560   \n",
       "3   2010  10  1810  1000000.0  164.5  164500000.0         18  61.680076   \n",
       "4   2010  10  1910  1980000.0  184.7  365706000.0         19  59.747472   \n",
       "\n",
       "                            ... tmean_median                                   \\\n",
       "Mn           5           6  ...            4          5          6          7   \n",
       "0   111.491847  158.227597  ...    63.895154  72.600094  80.407162  81.836860   \n",
       "1   117.693103  164.507182  ...    64.004156  72.494026  80.247550  81.856725   \n",
       "2    93.449041  133.389533  ...    54.400199  59.898352  71.408736  75.561266   \n",
       "3    93.111855  134.616544  ...    55.329140  60.157302  73.427448  75.252502   \n",
       "4    85.280898  126.621425  ...    54.598207  60.211175  69.662564  73.348930   \n",
       "\n",
       "                    tmin                                              \n",
       "Mn          8          4          5          6          7          8  \n",
       "0   82.698121  37.943095  46.667919  60.173894  61.110230  62.857805  \n",
       "1   81.734689  37.831221  44.635106  61.073172  61.285739  61.391250  \n",
       "2   74.875042  29.558627  34.148131  54.359674  55.136327  51.756197  \n",
       "3   74.974569  30.496707  35.351764  49.610917  53.269561  51.926810  \n",
       "4   74.895144  28.346277  30.802152  49.005702  59.023717  52.240249  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "df_ELN = df_gs.pivot_table(index=['Year', 'CRD', 'FIPS','Area','Yield','Total_yield','State_code'], \n",
    "                           columns=['Mn']).reset_index()\n",
    "df_ELN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6SmshQagbNlC",
    "outputId": "918482b4-616b-4b92-89b3-c9bb0fbb0fc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44087706, 0.36805012, 0.59005482, ..., 0.59005482, 0.40955364,\n",
       "       0.29757244])"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize to 1 and 0\n",
    "def min_max_norm(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "X = df_ELN.iloc[:, 7:]\n",
    "y = min_max_norm(df_ELN['Yield'].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "YnI270QMbfxU",
    "outputId": "96393911-00f7-477d-c916-62bf2993db18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0049819373390640465, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.005423408382746686, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0056464998328316085, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006668187749269805, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007184484227760635, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007314872444901255, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00807134058130643, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007999986893100441, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00795039093318195, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01223769549693543, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0128860872694041, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007901155700523077, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01276870751980752, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007807753604087253, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012930662831962536, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007690890691673502, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01276128089888573, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012689753811606863, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012281656575279243, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0119969390023833, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011798147677353654, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004941332285842037, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.004786801653128947, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006087917187389991, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006221912013536723, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006332898724451752, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006504343931759138, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00941983640452193, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006936715149677752, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006962897058286899, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0066491225240632446, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009913026057564167, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01011586321736857, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010522765011788948, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009937193745592765, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012932714509204857, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013763046777349075, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012794357942055967, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01202404928033829, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008287425797149695, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008852545852302995, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008539690486692564, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008391078249694317, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00820638228097792, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009269938114535137, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008023237555544682, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008247059847512617, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016046800876836187, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007821030111209382, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018715030869188354, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01828538224963694, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0097225378637944, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.006901675471791435, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010363321036027884, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010525646842282299, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010948312456122267, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01073652590418206, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009306088147258862, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01394936324902929, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013071539774383467, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012028413789824555, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009661544168597658, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008392558963560504, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017044594130748436, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018845931932219173, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008439706950017722, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018386800036481077, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008867540743441538, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010678408930594685, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008565670078144905, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008403366008931101, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00821201364139057, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0080247105972866, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007819019391739346, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007045080250861702, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010619759338830193, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010756770053511389, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011182746762596452, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010950357949667477, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010359594691102814, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012643264381544839, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013149135881302954, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012053334977697006, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008529833769141959, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00887340792327862, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009886784846575125, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008578677193767703, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008473778107457974, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008408763082357495, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017581205079881812, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008213923932679279, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018914138653730816, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008024499434920784, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018438614793911512, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00781717263690851, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011122131998313023, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007073349919856753, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01066766933421448, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010799799070049687, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011226140747240265, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010989107357808336, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010569807942918175, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012293337407545124, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013160774662065222, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012057537096051618, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008545677594447909, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00887441509367548, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008580942382941714, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008409642404043183, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009929204603402297, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008488773882188383, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008214177294735947, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017680898107450105, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008024377540184702, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018926315574208985, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007816775106203266, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018447791251702483, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011197591493750991, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007093919418988293, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01070264113132069, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010831201923544143, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011257754745653159, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011017195655167455, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01083763424807671, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012033465150381062, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013165043820393407, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012060532602539809, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009959940929512356, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00849968192252959, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.017753756797809217, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018935092708407097, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008558291800518703, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018454391663865977, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008874986891537873, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011251261250084355, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0085825801680528, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008410257217029482, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008214342180753675, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008024272392432863, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007816474752029734, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.007098816675188857, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010710964428810144, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010838668747691571, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011265270348744139, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008561025889321172, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011023850676313174, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.010841802086062557, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008875186142088154, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.011971728511245061, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008582955206723142, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013165917866142962, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008410401867962491, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.012061227302822886, tolerance: 0.003822807508056161\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008214378722826154, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008024245400768848, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.00781640202439604, tolerance: 0.0037242451908541824\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.009966852449014851, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.008502267038757338, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01777110504281154, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018937167449266212, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018455950130295662, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01126385946118802, tolerance: 0.003746686501385217\n",
      "  tol, rng, random, positive)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.04767632229043173, tolerance: 0.004624226667053713\n",
      "  positive)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=None, copy_X=True, cv=5, eps=0.001, fit_intercept=True,\n",
       "             l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000,\n",
       "             n_alphas=100, n_jobs=-1, normalize=False, positive=False,\n",
       "             precompute='auto', random_state=2020, selection='cyclic',\n",
       "             tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "elasticnet = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1], \n",
    "                          cv=5, verbose=0, n_jobs=-1, \n",
    "                          random_state=2020, selection='cyclic')\n",
    "elasticnet.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_BnVrdw2fS5z",
    "outputId": "b9a3aaf5-cc5e-4f02-c46d-403fa21651bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.68197023764588"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rescale back to original scale\n",
    "def rescale_back(x, original_x):\n",
    "    return (np.max(original_x) - np.min(original_x)) * x + np.min(original_x)\n",
    "\n",
    "y_hat = rescale_back(elasticnet.predict(X), df_ELN['Yield'].values)\n",
    "\n",
    "np.sqrt(mean_squared_error(df_ELN['Yield'].values, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "colab_type": "code",
    "id": "ih9x8zrMhCih",
    "outputId": "0d9781f7-2bb7-4be0-e737-31599ab3ef8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/pandas/core/groupby/generic.py:1455: FutureWarning: using a dict with renaming is deprecated and will be removed\n",
      "in a future version.\n",
      "\n",
      "For column-specific groupby renaming, use named aggregation\n",
      "\n",
      "    >>> df.groupby(...).agg(name=('column', aggfunc))\n",
      "\n",
      "  return super().aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Area</th>\n",
       "      <th>Total_yield_pred</th>\n",
       "      <th>ELN_pred</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>87173100.0</td>\n",
       "      <td>1.253098e+10</td>\n",
       "      <td>143.748257</td>\n",
       "      <td>152.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>90902100.0</td>\n",
       "      <td>1.240146e+10</td>\n",
       "      <td>136.426559</td>\n",
       "      <td>146.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>96171300.0</td>\n",
       "      <td>1.178909e+10</td>\n",
       "      <td>122.584299</td>\n",
       "      <td>123.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>94045400.0</td>\n",
       "      <td>1.389857e+10</td>\n",
       "      <td>147.785784</td>\n",
       "      <td>158.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>89506800.0</td>\n",
       "      <td>1.486642e+10</td>\n",
       "      <td>166.092665</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>86753700.0</td>\n",
       "      <td>1.314562e+10</td>\n",
       "      <td>151.528092</td>\n",
       "      <td>168.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>92770700.0</td>\n",
       "      <td>1.431118e+10</td>\n",
       "      <td>154.263957</td>\n",
       "      <td>174.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>88715700.0</td>\n",
       "      <td>1.387298e+10</td>\n",
       "      <td>156.375744</td>\n",
       "      <td>176.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>87386800.0</td>\n",
       "      <td>1.399404e+10</td>\n",
       "      <td>160.139115</td>\n",
       "      <td>176.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>88210700.0</td>\n",
       "      <td>1.367046e+10</td>\n",
       "      <td>154.975077</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year        Area  Total_yield_pred    ELN_pred  Value\n",
       "0  2010  87173100.0      1.253098e+10  143.748257  152.6\n",
       "1  2011  90902100.0      1.240146e+10  136.426559  146.8\n",
       "2  2012  96171300.0      1.178909e+10  122.584299  123.1\n",
       "3  2013  94045400.0      1.389857e+10  147.785784  158.1\n",
       "4  2014  89506800.0      1.486642e+10  166.092665  171.0\n",
       "5  2015  86753700.0      1.314562e+10  151.528092  168.4\n",
       "6  2016  92770700.0      1.431118e+10  154.263957  174.6\n",
       "7  2017  88715700.0      1.387298e+10  156.375744  176.6\n",
       "8  2018  87386800.0      1.399404e+10  160.139115  176.4\n",
       "9  2019  88210700.0      1.367046e+10  154.975077  168.0"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on non-missing FIPS-level dataset\n",
    "\n",
    "df_pred_gs = pd.merge(df_pred[df_pred['Mn'].isin([4,5,6,7,8])], df_gs[['Year', 'FIPS', 'Area']],\n",
    "                      on = ['Year', 'FIPS'])\n",
    "df_pred_ELN = df_pred_gs.pivot_table(index=['Year','FIPS','State_code', 'Area'], columns=['Mn']).reset_index()\n",
    "df_pred_ELN['ELN_pred'] = rescale_back(elasticnet.predict(df_pred_ELN.iloc[:, 4:]), df_ELN['Yield'].values)\n",
    "df_pred_ELN['Total_yield_pred'] = df_pred_ELN['ELN_pred'] * df_pred_ELN['Area']\n",
    "df_national_pred = df_pred_ELN.groupby(['Year']).agg({'Area':'sum', 'Total_yield_pred':'sum'}).reset_index()\n",
    "df_national_pred['ELN_pred'] = df_national_pred['Total_yield_pred'] / df_national_pred['Area'] \n",
    "df_national_pred = pd.merge(df_national_pred, target_df, on='Year')\n",
    "df_national_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "bSzC86VvjKVj",
    "outputId": "7a352402-a3c2-4481-9e4a-27c0cba09a12"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7sAAAFbCAYAAAAUQZldAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkiRJKjkmu5IkSZKkkvP/ZlUGG05cS+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1152x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m_std_err = np.sqrt(mean_squared_error(df_national_pred['Value'].values, df_national_pred['ELN_pred']))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "\n",
    "g = sns.lineplot(x='Year', y='Value', data=df_national_pred, label='True Yield')\n",
    "g = sns.lineplot(x='Year', y='ELN_pred', data=df_national_pred, label='ElasticNet Prediction')\n",
    "g.set_title(f\"Corn Yield Prediction Based on Growing Seasons (Mean Std Err: {m_std_err:.2f})\", fontsize=22)\n",
    "g.set_xlabel(\"Years\", fontsize=18)\n",
    "g.set_ylabel('Corn yield (bu/ac)', fontsize=18)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVYdq5Jay9Bb"
   },
   "source": [
    "<a id='section2'></a>\n",
    "## Time-series model to predict growing season weather\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "colab_type": "code",
    "id": "0lOWwY8iz4yF",
    "outputId": "8b55ad61-8332-4a99-e7ea-a52d1580b9f9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mn</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State_code</th>\n",
       "      <th>ppt_m</th>\n",
       "      <th>ppt_sum</th>\n",
       "      <th>ppt_max</th>\n",
       "      <th>ppt_min</th>\n",
       "      <th>ppt_median</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tmean_median</th>\n",
       "      <th>tdif_m</th>\n",
       "      <th>tdif_median</th>\n",
       "      <th>tdif_max</th>\n",
       "      <th>tdif_min</th>\n",
       "      <th>RDI</th>\n",
       "      <th>SPI</th>\n",
       "      <th>PET</th>\n",
       "      <th>SPEI</th>\n",
       "      <th>PNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>0.190513</td>\n",
       "      <td>0.173869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474922</td>\n",
       "      <td>0.446713</td>\n",
       "      <td>0.418833</td>\n",
       "      <td>0.409948</td>\n",
       "      <td>0.362115</td>\n",
       "      <td>0.375403</td>\n",
       "      <td>0.435803</td>\n",
       "      <td>0.148312</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.117250</td>\n",
       "      <td>0.173226</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.542076</td>\n",
       "      <td>0.520154</td>\n",
       "      <td>0.431505</td>\n",
       "      <td>0.435913</td>\n",
       "      <td>0.287017</td>\n",
       "      <td>0.265672</td>\n",
       "      <td>0.422274</td>\n",
       "      <td>0.120320</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.158777</td>\n",
       "      <td>0.153485</td>\n",
       "      <td>0.092774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.637660</td>\n",
       "      <td>0.555056</td>\n",
       "      <td>0.565264</td>\n",
       "      <td>0.581773</td>\n",
       "      <td>0.444284</td>\n",
       "      <td>0.507221</td>\n",
       "      <td>0.443169</td>\n",
       "      <td>0.097441</td>\n",
       "      <td>0.499987</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.083532</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070781</td>\n",
       "      <td>0.068422</td>\n",
       "      <td>0.125064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.720394</td>\n",
       "      <td>0.677334</td>\n",
       "      <td>0.700692</td>\n",
       "      <td>0.718692</td>\n",
       "      <td>0.602338</td>\n",
       "      <td>0.630821</td>\n",
       "      <td>0.440824</td>\n",
       "      <td>0.255097</td>\n",
       "      <td>0.117378</td>\n",
       "      <td>0.349898</td>\n",
       "      <td>0.239598</td>\n",
       "      <td>0.393341</td>\n",
       "      <td>0.186201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222818</td>\n",
       "      <td>0.222818</td>\n",
       "      <td>0.260075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051919</td>\n",
       "      <td>0.772019</td>\n",
       "      <td>0.751802</td>\n",
       "      <td>0.788614</td>\n",
       "      <td>0.806079</td>\n",
       "      <td>0.397383</td>\n",
       "      <td>0.431352</td>\n",
       "      <td>0.359925</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.209251</td>\n",
       "      <td>0.457043</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.456628</td>\n",
       "      <td>0.200032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34066</th>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.051836</td>\n",
       "      <td>0.048380</td>\n",
       "      <td>0.056704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.561073</td>\n",
       "      <td>0.316436</td>\n",
       "      <td>0.399498</td>\n",
       "      <td>0.413584</td>\n",
       "      <td>0.521909</td>\n",
       "      <td>0.562515</td>\n",
       "      <td>0.681239</td>\n",
       "      <td>0.154595</td>\n",
       "      <td>0.888837</td>\n",
       "      <td>0.637334</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.690010</td>\n",
       "      <td>0.299214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34067</th>\n",
       "      <td>2019</td>\n",
       "      <td>12</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.017402</td>\n",
       "      <td>0.016822</td>\n",
       "      <td>0.017208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.388095</td>\n",
       "      <td>0.393951</td>\n",
       "      <td>0.371779</td>\n",
       "      <td>0.390140</td>\n",
       "      <td>0.376418</td>\n",
       "      <td>0.412139</td>\n",
       "      <td>0.393089</td>\n",
       "      <td>0.244723</td>\n",
       "      <td>0.853996</td>\n",
       "      <td>0.520865</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.578777</td>\n",
       "      <td>0.216753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34068</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.005006</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.354570</td>\n",
       "      <td>0.401574</td>\n",
       "      <td>0.379872</td>\n",
       "      <td>0.381829</td>\n",
       "      <td>0.463565</td>\n",
       "      <td>0.486627</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>0.352777</td>\n",
       "      <td>0.751862</td>\n",
       "      <td>0.538608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.673526</td>\n",
       "      <td>0.228208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34069</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.015783</td>\n",
       "      <td>0.014205</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001026</td>\n",
       "      <td>0.511738</td>\n",
       "      <td>0.291494</td>\n",
       "      <td>0.337767</td>\n",
       "      <td>0.334820</td>\n",
       "      <td>0.507077</td>\n",
       "      <td>0.458560</td>\n",
       "      <td>0.565586</td>\n",
       "      <td>0.267997</td>\n",
       "      <td>0.888973</td>\n",
       "      <td>0.631940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645337</td>\n",
       "      <td>0.270919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34070</th>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.526632</td>\n",
       "      <td>0.492538</td>\n",
       "      <td>0.453144</td>\n",
       "      <td>0.455437</td>\n",
       "      <td>0.671134</td>\n",
       "      <td>0.681428</td>\n",
       "      <td>0.525950</td>\n",
       "      <td>0.474306</td>\n",
       "      <td>0.560039</td>\n",
       "      <td>0.295239</td>\n",
       "      <td>0.047438</td>\n",
       "      <td>0.382471</td>\n",
       "      <td>0.124644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34071 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Mn  FIPS  State_code  ...       SPI       PET      SPEI       PNP\n",
       "0      2010   1   110           1  ...  0.500000  0.002531  0.500000  0.000000\n",
       "1      2010   2   110           1  ...  0.500000  0.005024  0.500000  0.000000\n",
       "2      2010   3   110           1  ...  0.500000  0.083532  0.500000  0.000000\n",
       "3      2010   4   110           1  ...  0.349898  0.239598  0.393341  0.186201\n",
       "4      2010   5   110           1  ...  0.457043  0.407567  0.456628  0.200032\n",
       "...     ...  ..   ...         ...  ...       ...       ...       ...       ...\n",
       "34066  2019  11  5650          56  ...  0.637334  0.002405  0.690010  0.299214\n",
       "34067  2019  12  5650          56  ...  0.520865  0.000000  0.578777  0.216753\n",
       "34068  2020   1  5650          56  ...  0.538608  0.000000  0.673526  0.228208\n",
       "34069  2020   2  5650          56  ...  0.631940  0.000000  0.645337  0.270919\n",
       "34070  2020   3  5650          56  ...  0.295239  0.047438  0.382471  0.124644\n",
       "\n",
       "[34071 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Flatten, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "\n",
    "# normalize data\n",
    "df_norm = df_pred\n",
    "df_norm.iloc[:,4:] = df_pred.iloc[:,4:].apply(min_max_norm, axis=0)\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KR6wYyvWz4vl",
    "outputId": "bf8b4123-e36b-4e01-be07-bdfe5bb26f05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30470, 12, 18)\n",
      "(30470, 1, 18)\n"
     ]
    }
   ],
   "source": [
    "seq_len = 12 # 12 months as predictors\n",
    "\n",
    "# create input sequence\n",
    "input_sequences = []\n",
    "target = []\n",
    "\n",
    "for fips in df_norm['FIPS'].unique():\n",
    "    df_tmp = df_norm[df_norm['FIPS'] == fips].sort_values(['Year','Mn'])\n",
    "\n",
    "    for i in range(seq_len+1, df_tmp.shape[0]):\n",
    "        input_sequences.append(df_tmp.iloc[(i - seq_len - 1):(i-1), 4:].values)\n",
    "        target.append(df_tmp.iloc[(i-1):(i), 4:].values)\n",
    "\n",
    "input_sequences = np.array(input_sequences)\n",
    "target = np.array(target)\n",
    "\n",
    "print(input_sequences.shape)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "iTlLZljcGFdb",
    "outputId": "8574f263-8659-4392-ec8a-4643087a4be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30470, 18)\n"
     ]
    }
   ],
   "source": [
    "target = target.reshape(-1, 18)\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "bW32p0yMm3LO",
    "outputId": "8d751970-a401-44d8-c798-b26862b4b286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 32)                6528      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              33000     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                18018     \n",
      "=================================================================\n",
      "Total params: 57,546\n",
      "Trainable params: 57,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(seq_len, 18))) # 12 time steps and 18 features\n",
    "model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(1000, activation='relu', kernel_regularizer=l2(0.01),\n",
    "                bias_regularizer=l1(0.01)))\n",
    "model.add(Dense(18, activation='relu'))\n",
    "# Pick an optimizer\n",
    "adam = Adam(learning_rate=0.01)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mse'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "A9KslLfZzmY4",
    "outputId": "343e45c0-7e3c-44db-86a9-e3a66822bc8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 30470 samples\n",
      "Epoch 1/50\n",
      "30470/30470 [==============================] - 17s 560us/sample - loss: 0.0349 - mean_squared_error: 0.0159\n",
      "Epoch 2/50\n",
      "30470/30470 [==============================] - 17s 550us/sample - loss: 0.0232 - mean_squared_error: 0.0087\n",
      "Epoch 3/50\n",
      "30470/30470 [==============================] - 16s 538us/sample - loss: 0.0225 - mean_squared_error: 0.0082\n",
      "Epoch 4/50\n",
      "30470/30470 [==============================] - 16s 537us/sample - loss: 0.0225 - mean_squared_error: 0.0080\n",
      "Epoch 5/50\n",
      "30470/30470 [==============================] - 16s 534us/sample - loss: 0.0224 - mean_squared_error: 0.0079\n",
      "Epoch 6/50\n",
      "30470/30470 [==============================] - 16s 533us/sample - loss: 0.0223 - mean_squared_error: 0.0077\n",
      "Epoch 7/50\n",
      "30470/30470 [==============================] - 16s 521us/sample - loss: 0.0225 - mean_squared_error: 0.0077\n",
      "Epoch 8/50\n",
      "30470/30470 [==============================] - 16s 529us/sample - loss: 0.0223 - mean_squared_error: 0.0075\n",
      "Epoch 9/50\n",
      "30470/30470 [==============================] - 16s 524us/sample - loss: 0.0223 - mean_squared_error: 0.0075\n",
      "Epoch 10/50\n",
      "30470/30470 [==============================] - 16s 524us/sample - loss: 0.0220 - mean_squared_error: 0.0074\n",
      "Epoch 11/50\n",
      "30470/30470 [==============================] - 16s 511us/sample - loss: 0.0223 - mean_squared_error: 0.0074\n",
      "Epoch 12/50\n",
      "30470/30470 [==============================] - 16s 509us/sample - loss: 0.0219 - mean_squared_error: 0.0073\n",
      "Epoch 13/50\n",
      "30470/30470 [==============================] - 15s 507us/sample - loss: 0.0220 - mean_squared_error: 0.0073\n",
      "Epoch 14/50\n",
      "30470/30470 [==============================] - 16s 513us/sample - loss: 0.0219 - mean_squared_error: 0.0072\n",
      "Epoch 15/50\n",
      "30470/30470 [==============================] - 16s 512us/sample - loss: 0.0217 - mean_squared_error: 0.0071\n",
      "Epoch 16/50\n",
      "30470/30470 [==============================] - 15s 506us/sample - loss: 0.0219 - mean_squared_error: 0.0071\n",
      "Epoch 17/50\n",
      "30470/30470 [==============================] - 15s 507us/sample - loss: 0.0218 - mean_squared_error: 0.0071\n",
      "Epoch 18/50\n",
      "30470/30470 [==============================] - 16s 509us/sample - loss: 0.0217 - mean_squared_error: 0.0071\n",
      "Epoch 19/50\n",
      "30470/30470 [==============================] - 16s 512us/sample - loss: 0.0218 - mean_squared_error: 0.0070\n",
      "Epoch 20/50\n",
      "30470/30470 [==============================] - 15s 504us/sample - loss: 0.0217 - mean_squared_error: 0.0070\n",
      "Epoch 21/50\n",
      "30470/30470 [==============================] - 16s 512us/sample - loss: 0.0213 - mean_squared_error: 0.0069\n",
      "Epoch 22/50\n",
      "30470/30470 [==============================] - 15s 498us/sample - loss: 0.0216 - mean_squared_error: 0.0069\n",
      "Epoch 23/50\n",
      "30470/30470 [==============================] - 15s 499us/sample - loss: 0.0215 - mean_squared_error: 0.0069\n",
      "Epoch 24/50\n",
      "30470/30470 [==============================] - 15s 502us/sample - loss: 0.0215 - mean_squared_error: 0.0069\n",
      "Epoch 25/50\n",
      "30470/30470 [==============================] - 15s 506us/sample - loss: 0.0216 - mean_squared_error: 0.0069\n",
      "Epoch 26/50\n",
      "30470/30470 [==============================] - 15s 499us/sample - loss: 0.0214 - mean_squared_error: 0.0068\n",
      "Epoch 27/50\n",
      "30470/30470 [==============================] - 15s 496us/sample - loss: 0.0215 - mean_squared_error: 0.0068\n",
      "Epoch 28/50\n",
      "30470/30470 [==============================] - 15s 499us/sample - loss: 0.0213 - mean_squared_error: 0.0068\n",
      "Epoch 29/50\n",
      "30470/30470 [==============================] - 15s 496us/sample - loss: 0.0214 - mean_squared_error: 0.0067\n",
      "Epoch 30/50\n",
      "30470/30470 [==============================] - 15s 497us/sample - loss: 0.0213 - mean_squared_error: 0.0067\n",
      "Epoch 31/50\n",
      "30470/30470 [==============================] - 15s 494us/sample - loss: 0.0213 - mean_squared_error: 0.0068\n",
      "Epoch 32/50\n",
      "30470/30470 [==============================] - 15s 495us/sample - loss: 0.0214 - mean_squared_error: 0.0067\n",
      "Epoch 33/50\n",
      "30470/30470 [==============================] - 15s 493us/sample - loss: 0.0214 - mean_squared_error: 0.0067\n",
      "Epoch 34/50\n",
      "30470/30470 [==============================] - 15s 497us/sample - loss: 0.0215 - mean_squared_error: 0.0068\n",
      "Epoch 35/50\n",
      "30470/30470 [==============================] - 15s 498us/sample - loss: 0.0213 - mean_squared_error: 0.0067\n",
      "Epoch 36/50\n",
      "30470/30470 [==============================] - 15s 496us/sample - loss: 0.0213 - mean_squared_error: 0.0067\n",
      "Epoch 37/50\n",
      "30470/30470 [==============================] - 15s 496us/sample - loss: 0.0213 - mean_squared_error: 0.0067\n",
      "Epoch 38/50\n",
      "30470/30470 [==============================] - 15s 488us/sample - loss: 0.0213 - mean_squared_error: 0.0067\n",
      "Epoch 39/50\n",
      "30470/30470 [==============================] - 15s 497us/sample - loss: 0.0213 - mean_squared_error: 0.0067\n",
      "Epoch 40/50\n",
      "30470/30470 [==============================] - 15s 494us/sample - loss: 0.0212 - mean_squared_error: 0.0067\n",
      "Epoch 41/50\n",
      "30470/30470 [==============================] - 15s 502us/sample - loss: 0.0212 - mean_squared_error: 0.0066\n",
      "Epoch 42/50\n",
      "30470/30470 [==============================] - 15s 504us/sample - loss: 0.0212 - mean_squared_error: 0.0066\n",
      "Epoch 43/50\n",
      "30470/30470 [==============================] - 15s 495us/sample - loss: 0.0212 - mean_squared_error: 0.0066\n",
      "Epoch 44/50\n",
      "30470/30470 [==============================] - 15s 492us/sample - loss: 0.0213 - mean_squared_error: 0.0066\n",
      "Epoch 45/50\n",
      "30470/30470 [==============================] - 15s 495us/sample - loss: 0.0212 - mean_squared_error: 0.0066\n",
      "Epoch 46/50\n",
      "30470/30470 [==============================] - 15s 501us/sample - loss: 0.0213 - mean_squared_error: 0.0066\n",
      "Epoch 47/50\n",
      "30470/30470 [==============================] - 15s 494us/sample - loss: 0.0212 - mean_squared_error: 0.0066\n",
      "Epoch 48/50\n",
      "30470/30470 [==============================] - 15s 496us/sample - loss: 0.0213 - mean_squared_error: 0.0066\n",
      "Epoch 49/50\n",
      "30470/30470 [==============================] - 15s 495us/sample - loss: 0.0210 - mean_squared_error: 0.0066\n",
      "Epoch 50/50\n",
      "30470/30470 [==============================] - 15s 498us/sample - loss: 0.0213 - mean_squared_error: 0.0066\n"
     ]
    }
   ],
   "source": [
    " history = model.fit(input_sequences, target, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "DzImTRO8GvXn",
    "outputId": "d96f4b35-d154-477b-9167-941c7484c6ed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8QAAAGRCAYAAACjcHqaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD/kuDJG7ZkElAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['mean_squared_error']\n",
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, acc, 'b', label='mean_squared_error')\n",
    "plt.title('Training mean squared error', fontsize=22)\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.ylabel('mean_squared_error', fontsize=18)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.title('Training loss', fontsize=22)\n",
    "plt.ylabel('loss', fontsize=18)\n",
    "plt.xlabel('Epochs', fontsize=18)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "colab_type": "code",
    "id": "mZxgYFYlJoG5",
    "outputId": "210bec22-a707-4b3d-b067-852204aad43c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Mn</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State_code</th>\n",
       "      <th>ppt_m</th>\n",
       "      <th>ppt_sum</th>\n",
       "      <th>ppt_max</th>\n",
       "      <th>ppt_min</th>\n",
       "      <th>ppt_median</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmean</th>\n",
       "      <th>tmean_median</th>\n",
       "      <th>tdif_m</th>\n",
       "      <th>tdif_median</th>\n",
       "      <th>tdif_max</th>\n",
       "      <th>tdif_min</th>\n",
       "      <th>RDI</th>\n",
       "      <th>SPI</th>\n",
       "      <th>PET</th>\n",
       "      <th>SPEI</th>\n",
       "      <th>PNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.146449</td>\n",
       "      <td>0.131869</td>\n",
       "      <td>0.099933</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.906811</td>\n",
       "      <td>0.982486</td>\n",
       "      <td>0.973226</td>\n",
       "      <td>0.980479</td>\n",
       "      <td>0.443165</td>\n",
       "      <td>0.455591</td>\n",
       "      <td>0.284369</td>\n",
       "      <td>0.433993</td>\n",
       "      <td>0.097096</td>\n",
       "      <td>0.847796</td>\n",
       "      <td>0.756851</td>\n",
       "      <td>0.861315</td>\n",
       "      <td>0.382992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145834</td>\n",
       "      <td>0.128108</td>\n",
       "      <td>0.078367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.969459</td>\n",
       "      <td>1.140674</td>\n",
       "      <td>1.120713</td>\n",
       "      <td>1.131143</td>\n",
       "      <td>0.405775</td>\n",
       "      <td>0.403621</td>\n",
       "      <td>0.201430</td>\n",
       "      <td>0.518389</td>\n",
       "      <td>0.090787</td>\n",
       "      <td>0.848093</td>\n",
       "      <td>0.994606</td>\n",
       "      <td>0.846661</td>\n",
       "      <td>0.367518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102788</td>\n",
       "      <td>0.090925</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987710</td>\n",
       "      <td>1.089395</td>\n",
       "      <td>1.094389</td>\n",
       "      <td>1.107271</td>\n",
       "      <td>0.506403</td>\n",
       "      <td>0.503014</td>\n",
       "      <td>0.288576</td>\n",
       "      <td>0.574139</td>\n",
       "      <td>0.301164</td>\n",
       "      <td>0.488799</td>\n",
       "      <td>0.938179</td>\n",
       "      <td>0.468222</td>\n",
       "      <td>0.201402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.145414</td>\n",
       "      <td>0.133176</td>\n",
       "      <td>0.088996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005867</td>\n",
       "      <td>1.179575</td>\n",
       "      <td>1.169828</td>\n",
       "      <td>1.180894</td>\n",
       "      <td>0.388165</td>\n",
       "      <td>0.387268</td>\n",
       "      <td>0.173124</td>\n",
       "      <td>0.517035</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475163</td>\n",
       "      <td>1.049743</td>\n",
       "      <td>0.460150</td>\n",
       "      <td>0.186048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144064</td>\n",
       "      <td>0.132944</td>\n",
       "      <td>0.101445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.943292</td>\n",
       "      <td>1.051956</td>\n",
       "      <td>1.051239</td>\n",
       "      <td>1.060431</td>\n",
       "      <td>0.411515</td>\n",
       "      <td>0.417771</td>\n",
       "      <td>0.241495</td>\n",
       "      <td>0.440544</td>\n",
       "      <td>0.204478</td>\n",
       "      <td>0.425450</td>\n",
       "      <td>0.852329</td>\n",
       "      <td>0.412897</td>\n",
       "      <td>0.171499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778173</td>\n",
       "      <td>0.660738</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.706999</td>\n",
       "      <td>0.738092</td>\n",
       "      <td>0.759637</td>\n",
       "      <td>0.562630</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.413491</td>\n",
       "      <td>0.373556</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.878784</td>\n",
       "      <td>0.790746</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.868937</td>\n",
       "      <td>0.757608</td>\n",
       "      <td>0.758660</td>\n",
       "      <td>0.524402</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>0.563425</td>\n",
       "      <td>0.041807</td>\n",
       "      <td>0.028904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.078888</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.895730</td>\n",
       "      <td>0.918526</td>\n",
       "      <td>0.935415</td>\n",
       "      <td>0.946862</td>\n",
       "      <td>0.538570</td>\n",
       "      <td>0.546210</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.455668</td>\n",
       "      <td>0.263546</td>\n",
       "      <td>0.301222</td>\n",
       "      <td>0.681905</td>\n",
       "      <td>0.288119</td>\n",
       "      <td>0.129663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>7</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.003647</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896090</td>\n",
       "      <td>0.862593</td>\n",
       "      <td>0.901240</td>\n",
       "      <td>0.913040</td>\n",
       "      <td>0.672737</td>\n",
       "      <td>0.678653</td>\n",
       "      <td>0.455930</td>\n",
       "      <td>0.532990</td>\n",
       "      <td>0.083477</td>\n",
       "      <td>0.254244</td>\n",
       "      <td>0.628636</td>\n",
       "      <td>0.241923</td>\n",
       "      <td>0.113519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>0.026731</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884397</td>\n",
       "      <td>0.863937</td>\n",
       "      <td>0.895208</td>\n",
       "      <td>0.906227</td>\n",
       "      <td>0.630218</td>\n",
       "      <td>0.638948</td>\n",
       "      <td>0.431993</td>\n",
       "      <td>0.504359</td>\n",
       "      <td>0.167074</td>\n",
       "      <td>0.328257</td>\n",
       "      <td>0.622690</td>\n",
       "      <td>0.314448</td>\n",
       "      <td>0.140756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1385 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Mn  FIPS  State_code  ...       SPI       PET      SPEI       PNP\n",
       "0   2020   4   110           1  ...  0.847796  0.756851  0.861315  0.382992\n",
       "1   2020   5   110           1  ...  0.848093  0.994606  0.846661  0.367518\n",
       "2   2020   6   110           1  ...  0.488799  0.938179  0.468222  0.201402\n",
       "3   2020   7   110           1  ...  0.475163  1.049743  0.460150  0.186048\n",
       "4   2020   8   110           1  ...  0.425450  0.852329  0.412897  0.171499\n",
       "..   ...  ..   ...         ...  ...       ...       ...       ...       ...\n",
       "0   2020   4  5650          56  ...  0.413491  0.373556  0.408900  0.208741\n",
       "1   2020   5  5650          56  ...  0.042299  0.563425  0.041807  0.028904\n",
       "2   2020   6  5650          56  ...  0.301222  0.681905  0.288119  0.129663\n",
       "3   2020   7  5650          56  ...  0.254244  0.628636  0.241923  0.113519\n",
       "4   2020   8  5650          56  ...  0.328257  0.622690  0.314448  0.140756\n",
       "\n",
       "[1385 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict til 2020.08\n",
    "weather_predict = pd.DataFrame()\n",
    "  \n",
    "for fips in df_pred['FIPS'].unique():\n",
    "    # get data from 2019.4 to 2020.3 for each FIPS\n",
    "    df_tmp = df_pred[df_pred['FIPS'] == fips].sort_values(['Year','Mn']).iloc[-12:,:]\n",
    "    state_code = df_tmp['State_code'].unique()[0]\n",
    "    last_month = df_tmp['Mn'].values[-1]\n",
    "    pred_len = 8 - last_month\n",
    "\n",
    "    # predict for 2020.4 to 2020.8\n",
    "    y_hat = []\n",
    "    tmp_x = df_tmp.iloc[:,4:].values.reshape(-1,12,18)\n",
    "    for i in range(pred_len):\n",
    "        tmp_y = model.predict(tmp_x, verbose=0)\n",
    "        y_hat.append(tmp_y.reshape(18))\n",
    "        # add prediction to time-series\n",
    "        tmp_x = np.concatenate((tmp_x.reshape(12,18), tmp_y), axis=0)\n",
    "        # remove the earliest month\n",
    "        tmp_x = tmp_x[1:,:].reshape(-1,12,18)\n",
    "    \n",
    "    df1 = pd.DataFrame({'Year': [2020] * pred_len,\n",
    "                        'Mn': np.arange(last_month+1, 9),\n",
    "                        'FIPS': [fips] * pred_len,\n",
    "                        'State_code': [state_code] * pred_len})\n",
    "    df2 = pd.DataFrame(np.array(y_hat), columns=df_tmp.columns[4:])\n",
    "    df3 = pd.concat((df1, df2), axis=1)\n",
    "    weather_predict = pd.concat((weather_predict,df3))\n",
    "    \n",
    "weather_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "fvahK3HJgRd6",
    "outputId": "96781a39-d753-445a-ab90-2b234e67ba1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110</td>\n",
       "      <td>136700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>53640.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>20570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>27260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>17770.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS      Area\n",
       "0   110  136700.0\n",
       "1   120   53640.0\n",
       "2   130   20570.0\n",
       "3   140   27260.0\n",
       "4   150   17770.0"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if assume 2020 planted area is the average of previous years\n",
    "fips_area = df_gs[['FIPS', 'Area']].groupby(['FIPS'])['Area'].mean().reset_index()\n",
    "fips_area.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "-hIcrBFeLjHM",
    "outputId": "b3859831-1f87-46a5-f2e9-d01b58c732c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>State_code</th>\n",
       "      <th>Area</th>\n",
       "      <th colspan=\"5\" halign=\"left\">PET</th>\n",
       "      <th colspan=\"5\" halign=\"left\">PNP</th>\n",
       "      <th colspan=\"5\" halign=\"left\">RDI</th>\n",
       "      <th colspan=\"5\" halign=\"left\">SPEI</th>\n",
       "      <th colspan=\"5\" halign=\"left\">SPI</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ppt_m</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ppt_max</th>\n",
       "      <th>ppt_median</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tdif_m</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tdif_max</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tdif_median</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tdif_min</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tmax</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tmean</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tmean_median</th>\n",
       "      <th colspan=\"5\" halign=\"left\">tmin</th>\n",
       "      <th>ELN_pred</th>\n",
       "      <th>Total_yield_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mn</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>136700.000000</td>\n",
       "      <td>0.756851</td>\n",
       "      <td>0.994606</td>\n",
       "      <td>0.938179</td>\n",
       "      <td>1.049743</td>\n",
       "      <td>0.852329</td>\n",
       "      <td>0.382992</td>\n",
       "      <td>0.367518</td>\n",
       "      <td>0.201402</td>\n",
       "      <td>0.186048</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.097096</td>\n",
       "      <td>0.090787</td>\n",
       "      <td>0.301164</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204478</td>\n",
       "      <td>0.861315</td>\n",
       "      <td>0.846661</td>\n",
       "      <td>0.468222</td>\n",
       "      <td>0.460150</td>\n",
       "      <td>0.412897</td>\n",
       "      <td>0.847796</td>\n",
       "      <td>0.848093</td>\n",
       "      <td>0.488799</td>\n",
       "      <td>0.475163</td>\n",
       "      <td>0.425450</td>\n",
       "      <td>0.146449</td>\n",
       "      <td>0.145834</td>\n",
       "      <td>0.102788</td>\n",
       "      <td>0.145414</td>\n",
       "      <td>0.144064</td>\n",
       "      <td>0.099933</td>\n",
       "      <td>0.078367</td>\n",
       "      <td>0.062372</td>\n",
       "      <td>0.088996</td>\n",
       "      <td>0.101445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506403</td>\n",
       "      <td>0.388165</td>\n",
       "      <td>0.411515</td>\n",
       "      <td>0.284369</td>\n",
       "      <td>0.201430</td>\n",
       "      <td>0.288576</td>\n",
       "      <td>0.173124</td>\n",
       "      <td>0.241495</td>\n",
       "      <td>0.455591</td>\n",
       "      <td>0.403621</td>\n",
       "      <td>0.503014</td>\n",
       "      <td>0.387268</td>\n",
       "      <td>0.417771</td>\n",
       "      <td>0.433993</td>\n",
       "      <td>0.518389</td>\n",
       "      <td>0.574139</td>\n",
       "      <td>0.517035</td>\n",
       "      <td>0.440544</td>\n",
       "      <td>0.906811</td>\n",
       "      <td>0.969459</td>\n",
       "      <td>0.987710</td>\n",
       "      <td>1.005867</td>\n",
       "      <td>0.943292</td>\n",
       "      <td>0.973226</td>\n",
       "      <td>1.120713</td>\n",
       "      <td>1.094389</td>\n",
       "      <td>1.169828</td>\n",
       "      <td>1.051239</td>\n",
       "      <td>0.980479</td>\n",
       "      <td>1.131143</td>\n",
       "      <td>1.107271</td>\n",
       "      <td>1.180894</td>\n",
       "      <td>1.060431</td>\n",
       "      <td>0.982486</td>\n",
       "      <td>1.140674</td>\n",
       "      <td>1.089395</td>\n",
       "      <td>1.179575</td>\n",
       "      <td>1.051956</td>\n",
       "      <td>149.404142</td>\n",
       "      <td>2.042355e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>53640.000000</td>\n",
       "      <td>0.733979</td>\n",
       "      <td>0.964908</td>\n",
       "      <td>0.898995</td>\n",
       "      <td>1.030163</td>\n",
       "      <td>0.852578</td>\n",
       "      <td>0.389013</td>\n",
       "      <td>0.356623</td>\n",
       "      <td>0.219813</td>\n",
       "      <td>0.192184</td>\n",
       "      <td>0.168592</td>\n",
       "      <td>0.193970</td>\n",
       "      <td>0.137105</td>\n",
       "      <td>0.368638</td>\n",
       "      <td>0.035307</td>\n",
       "      <td>0.196689</td>\n",
       "      <td>0.873064</td>\n",
       "      <td>0.820744</td>\n",
       "      <td>0.509316</td>\n",
       "      <td>0.471031</td>\n",
       "      <td>0.405309</td>\n",
       "      <td>0.860245</td>\n",
       "      <td>0.823830</td>\n",
       "      <td>0.530119</td>\n",
       "      <td>0.487353</td>\n",
       "      <td>0.417908</td>\n",
       "      <td>0.152211</td>\n",
       "      <td>0.145800</td>\n",
       "      <td>0.097280</td>\n",
       "      <td>0.147675</td>\n",
       "      <td>0.140879</td>\n",
       "      <td>0.105496</td>\n",
       "      <td>0.081450</td>\n",
       "      <td>0.059904</td>\n",
       "      <td>0.091419</td>\n",
       "      <td>0.099884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.525584</td>\n",
       "      <td>0.391787</td>\n",
       "      <td>0.417789</td>\n",
       "      <td>0.291026</td>\n",
       "      <td>0.213560</td>\n",
       "      <td>0.310833</td>\n",
       "      <td>0.180596</td>\n",
       "      <td>0.245765</td>\n",
       "      <td>0.454639</td>\n",
       "      <td>0.412703</td>\n",
       "      <td>0.523323</td>\n",
       "      <td>0.391995</td>\n",
       "      <td>0.423807</td>\n",
       "      <td>0.420877</td>\n",
       "      <td>0.510481</td>\n",
       "      <td>0.572035</td>\n",
       "      <td>0.512678</td>\n",
       "      <td>0.444354</td>\n",
       "      <td>0.898962</td>\n",
       "      <td>0.960735</td>\n",
       "      <td>0.974452</td>\n",
       "      <td>1.000838</td>\n",
       "      <td>0.944843</td>\n",
       "      <td>0.961090</td>\n",
       "      <td>1.102778</td>\n",
       "      <td>1.069162</td>\n",
       "      <td>1.158277</td>\n",
       "      <td>1.051334</td>\n",
       "      <td>0.968943</td>\n",
       "      <td>1.113102</td>\n",
       "      <td>1.082067</td>\n",
       "      <td>1.169316</td>\n",
       "      <td>1.060553</td>\n",
       "      <td>0.969951</td>\n",
       "      <td>1.121134</td>\n",
       "      <td>1.061708</td>\n",
       "      <td>1.167569</td>\n",
       "      <td>1.051016</td>\n",
       "      <td>149.379494</td>\n",
       "      <td>8.012716e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>20570.000000</td>\n",
       "      <td>0.812660</td>\n",
       "      <td>0.938105</td>\n",
       "      <td>0.822749</td>\n",
       "      <td>0.945505</td>\n",
       "      <td>0.702250</td>\n",
       "      <td>0.494230</td>\n",
       "      <td>0.462555</td>\n",
       "      <td>0.234277</td>\n",
       "      <td>0.204969</td>\n",
       "      <td>0.226822</td>\n",
       "      <td>0.230951</td>\n",
       "      <td>0.444909</td>\n",
       "      <td>0.543931</td>\n",
       "      <td>0.155807</td>\n",
       "      <td>0.412360</td>\n",
       "      <td>1.084382</td>\n",
       "      <td>1.036687</td>\n",
       "      <td>0.543412</td>\n",
       "      <td>0.501770</td>\n",
       "      <td>0.559732</td>\n",
       "      <td>1.060622</td>\n",
       "      <td>1.033393</td>\n",
       "      <td>0.564375</td>\n",
       "      <td>0.519150</td>\n",
       "      <td>0.572674</td>\n",
       "      <td>0.201142</td>\n",
       "      <td>0.194971</td>\n",
       "      <td>0.096918</td>\n",
       "      <td>0.155590</td>\n",
       "      <td>0.174386</td>\n",
       "      <td>0.135999</td>\n",
       "      <td>0.115994</td>\n",
       "      <td>0.067285</td>\n",
       "      <td>0.101743</td>\n",
       "      <td>0.125732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544078</td>\n",
       "      <td>0.389932</td>\n",
       "      <td>0.376178</td>\n",
       "      <td>0.188031</td>\n",
       "      <td>0.185343</td>\n",
       "      <td>0.341992</td>\n",
       "      <td>0.201319</td>\n",
       "      <td>0.250831</td>\n",
       "      <td>0.354232</td>\n",
       "      <td>0.344876</td>\n",
       "      <td>0.544011</td>\n",
       "      <td>0.393384</td>\n",
       "      <td>0.389817</td>\n",
       "      <td>0.394609</td>\n",
       "      <td>0.453772</td>\n",
       "      <td>0.550827</td>\n",
       "      <td>0.474594</td>\n",
       "      <td>0.346965</td>\n",
       "      <td>0.890128</td>\n",
       "      <td>0.939095</td>\n",
       "      <td>0.947897</td>\n",
       "      <td>0.968620</td>\n",
       "      <td>0.875896</td>\n",
       "      <td>1.006451</td>\n",
       "      <td>1.092003</td>\n",
       "      <td>1.022590</td>\n",
       "      <td>1.106483</td>\n",
       "      <td>0.962153</td>\n",
       "      <td>1.018285</td>\n",
       "      <td>1.103631</td>\n",
       "      <td>1.036295</td>\n",
       "      <td>1.116831</td>\n",
       "      <td>0.970036</td>\n",
       "      <td>1.037778</td>\n",
       "      <td>1.124718</td>\n",
       "      <td>1.012034</td>\n",
       "      <td>1.114408</td>\n",
       "      <td>0.964909</td>\n",
       "      <td>151.725168</td>\n",
       "      <td>3.120987e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>27260.000000</td>\n",
       "      <td>0.785299</td>\n",
       "      <td>0.876055</td>\n",
       "      <td>0.707061</td>\n",
       "      <td>0.789213</td>\n",
       "      <td>0.653302</td>\n",
       "      <td>0.495382</td>\n",
       "      <td>0.480947</td>\n",
       "      <td>0.251637</td>\n",
       "      <td>0.249914</td>\n",
       "      <td>0.232469</td>\n",
       "      <td>0.229329</td>\n",
       "      <td>0.474029</td>\n",
       "      <td>0.601022</td>\n",
       "      <td>0.386896</td>\n",
       "      <td>0.503922</td>\n",
       "      <td>1.088064</td>\n",
       "      <td>1.072752</td>\n",
       "      <td>0.581878</td>\n",
       "      <td>0.611015</td>\n",
       "      <td>0.568181</td>\n",
       "      <td>1.064193</td>\n",
       "      <td>1.068179</td>\n",
       "      <td>0.598765</td>\n",
       "      <td>0.626243</td>\n",
       "      <td>0.580737</td>\n",
       "      <td>0.206880</td>\n",
       "      <td>0.205373</td>\n",
       "      <td>0.107049</td>\n",
       "      <td>0.176656</td>\n",
       "      <td>0.173707</td>\n",
       "      <td>0.141954</td>\n",
       "      <td>0.126687</td>\n",
       "      <td>0.084294</td>\n",
       "      <td>0.125121</td>\n",
       "      <td>0.131342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530012</td>\n",
       "      <td>0.374439</td>\n",
       "      <td>0.382041</td>\n",
       "      <td>0.186679</td>\n",
       "      <td>0.189915</td>\n",
       "      <td>0.359781</td>\n",
       "      <td>0.228442</td>\n",
       "      <td>0.269310</td>\n",
       "      <td>0.344649</td>\n",
       "      <td>0.329169</td>\n",
       "      <td>0.537219</td>\n",
       "      <td>0.384280</td>\n",
       "      <td>0.396638</td>\n",
       "      <td>0.370575</td>\n",
       "      <td>0.409340</td>\n",
       "      <td>0.483073</td>\n",
       "      <td>0.387421</td>\n",
       "      <td>0.334889</td>\n",
       "      <td>0.877568</td>\n",
       "      <td>0.915107</td>\n",
       "      <td>0.903512</td>\n",
       "      <td>0.908631</td>\n",
       "      <td>0.857170</td>\n",
       "      <td>0.990154</td>\n",
       "      <td>1.056980</td>\n",
       "      <td>0.952331</td>\n",
       "      <td>1.015886</td>\n",
       "      <td>0.928807</td>\n",
       "      <td>1.001632</td>\n",
       "      <td>1.067636</td>\n",
       "      <td>0.964887</td>\n",
       "      <td>1.024928</td>\n",
       "      <td>0.936591</td>\n",
       "      <td>1.022284</td>\n",
       "      <td>1.089277</td>\n",
       "      <td>0.940473</td>\n",
       "      <td>1.022187</td>\n",
       "      <td>0.930841</td>\n",
       "      <td>151.492804</td>\n",
       "      <td>4.129694e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>17770.000000</td>\n",
       "      <td>0.924797</td>\n",
       "      <td>0.811271</td>\n",
       "      <td>0.728030</td>\n",
       "      <td>0.781907</td>\n",
       "      <td>0.651420</td>\n",
       "      <td>0.519569</td>\n",
       "      <td>0.436901</td>\n",
       "      <td>0.271331</td>\n",
       "      <td>0.291906</td>\n",
       "      <td>0.208504</td>\n",
       "      <td>0.258969</td>\n",
       "      <td>0.419075</td>\n",
       "      <td>0.598072</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.466693</td>\n",
       "      <td>1.157561</td>\n",
       "      <td>0.983145</td>\n",
       "      <td>0.639921</td>\n",
       "      <td>0.725452</td>\n",
       "      <td>0.498176</td>\n",
       "      <td>1.128512</td>\n",
       "      <td>0.981288</td>\n",
       "      <td>0.653218</td>\n",
       "      <td>0.726916</td>\n",
       "      <td>0.510639</td>\n",
       "      <td>0.247483</td>\n",
       "      <td>0.145749</td>\n",
       "      <td>0.166136</td>\n",
       "      <td>0.212753</td>\n",
       "      <td>0.162438</td>\n",
       "      <td>0.162123</td>\n",
       "      <td>0.084994</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>0.145019</td>\n",
       "      <td>0.124728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411341</td>\n",
       "      <td>0.271909</td>\n",
       "      <td>0.406909</td>\n",
       "      <td>0.089955</td>\n",
       "      <td>0.287873</td>\n",
       "      <td>0.280224</td>\n",
       "      <td>0.154206</td>\n",
       "      <td>0.288866</td>\n",
       "      <td>0.256348</td>\n",
       "      <td>0.453441</td>\n",
       "      <td>0.420605</td>\n",
       "      <td>0.286696</td>\n",
       "      <td>0.422079</td>\n",
       "      <td>0.367626</td>\n",
       "      <td>0.456159</td>\n",
       "      <td>0.400586</td>\n",
       "      <td>0.314292</td>\n",
       "      <td>0.349919</td>\n",
       "      <td>0.909593</td>\n",
       "      <td>0.916405</td>\n",
       "      <td>0.895292</td>\n",
       "      <td>0.875410</td>\n",
       "      <td>0.863803</td>\n",
       "      <td>1.078470</td>\n",
       "      <td>1.014707</td>\n",
       "      <td>0.971692</td>\n",
       "      <td>1.007873</td>\n",
       "      <td>0.925364</td>\n",
       "      <td>1.091309</td>\n",
       "      <td>1.025218</td>\n",
       "      <td>0.982159</td>\n",
       "      <td>1.017091</td>\n",
       "      <td>0.932812</td>\n",
       "      <td>1.128895</td>\n",
       "      <td>1.025658</td>\n",
       "      <td>0.973602</td>\n",
       "      <td>1.031727</td>\n",
       "      <td>0.924183</td>\n",
       "      <td>151.391842</td>\n",
       "      <td>2.690233e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2020</td>\n",
       "      <td>5580</td>\n",
       "      <td>55</td>\n",
       "      <td>827600.000000</td>\n",
       "      <td>0.337414</td>\n",
       "      <td>0.532228</td>\n",
       "      <td>0.605253</td>\n",
       "      <td>0.755282</td>\n",
       "      <td>0.646047</td>\n",
       "      <td>0.314003</td>\n",
       "      <td>0.395434</td>\n",
       "      <td>0.288080</td>\n",
       "      <td>0.257118</td>\n",
       "      <td>0.194510</td>\n",
       "      <td>0.760369</td>\n",
       "      <td>0.625395</td>\n",
       "      <td>0.647558</td>\n",
       "      <td>0.442698</td>\n",
       "      <td>0.436950</td>\n",
       "      <td>0.660436</td>\n",
       "      <td>0.853389</td>\n",
       "      <td>0.687368</td>\n",
       "      <td>0.621491</td>\n",
       "      <td>0.449327</td>\n",
       "      <td>0.663107</td>\n",
       "      <td>0.851626</td>\n",
       "      <td>0.694717</td>\n",
       "      <td>0.634031</td>\n",
       "      <td>0.467197</td>\n",
       "      <td>0.133202</td>\n",
       "      <td>0.193795</td>\n",
       "      <td>0.195044</td>\n",
       "      <td>0.173785</td>\n",
       "      <td>0.133376</td>\n",
       "      <td>0.114289</td>\n",
       "      <td>0.164771</td>\n",
       "      <td>0.147792</td>\n",
       "      <td>0.124067</td>\n",
       "      <td>0.103964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349672</td>\n",
       "      <td>0.375249</td>\n",
       "      <td>0.460316</td>\n",
       "      <td>0.474716</td>\n",
       "      <td>0.300075</td>\n",
       "      <td>0.265141</td>\n",
       "      <td>0.245201</td>\n",
       "      <td>0.327238</td>\n",
       "      <td>0.561078</td>\n",
       "      <td>0.400419</td>\n",
       "      <td>0.366096</td>\n",
       "      <td>0.385036</td>\n",
       "      <td>0.472967</td>\n",
       "      <td>0.281950</td>\n",
       "      <td>0.284161</td>\n",
       "      <td>0.299183</td>\n",
       "      <td>0.386947</td>\n",
       "      <td>0.394430</td>\n",
       "      <td>0.759662</td>\n",
       "      <td>0.803928</td>\n",
       "      <td>0.832358</td>\n",
       "      <td>0.889873</td>\n",
       "      <td>0.869370</td>\n",
       "      <td>0.713467</td>\n",
       "      <td>0.847360</td>\n",
       "      <td>0.899978</td>\n",
       "      <td>0.985488</td>\n",
       "      <td>0.919328</td>\n",
       "      <td>0.721651</td>\n",
       "      <td>0.854227</td>\n",
       "      <td>0.909160</td>\n",
       "      <td>0.994560</td>\n",
       "      <td>0.928021</td>\n",
       "      <td>0.694126</td>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.909874</td>\n",
       "      <td>0.995345</td>\n",
       "      <td>0.912529</td>\n",
       "      <td>150.883983</td>\n",
       "      <td>1.248716e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2020</td>\n",
       "      <td>5590</td>\n",
       "      <td>55</td>\n",
       "      <td>245050.000000</td>\n",
       "      <td>0.266447</td>\n",
       "      <td>0.428109</td>\n",
       "      <td>0.507910</td>\n",
       "      <td>0.664389</td>\n",
       "      <td>0.646731</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.369639</td>\n",
       "      <td>0.298811</td>\n",
       "      <td>0.263563</td>\n",
       "      <td>0.176130</td>\n",
       "      <td>0.721203</td>\n",
       "      <td>0.642139</td>\n",
       "      <td>0.689537</td>\n",
       "      <td>0.517595</td>\n",
       "      <td>0.214887</td>\n",
       "      <td>0.619140</td>\n",
       "      <td>0.782937</td>\n",
       "      <td>0.708410</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.405625</td>\n",
       "      <td>0.623458</td>\n",
       "      <td>0.785130</td>\n",
       "      <td>0.715085</td>\n",
       "      <td>0.637359</td>\n",
       "      <td>0.420517</td>\n",
       "      <td>0.124160</td>\n",
       "      <td>0.151698</td>\n",
       "      <td>0.190124</td>\n",
       "      <td>0.147313</td>\n",
       "      <td>0.101982</td>\n",
       "      <td>0.107997</td>\n",
       "      <td>0.139006</td>\n",
       "      <td>0.148879</td>\n",
       "      <td>0.109075</td>\n",
       "      <td>0.078909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363040</td>\n",
       "      <td>0.439825</td>\n",
       "      <td>0.499418</td>\n",
       "      <td>0.502369</td>\n",
       "      <td>0.383245</td>\n",
       "      <td>0.298096</td>\n",
       "      <td>0.309301</td>\n",
       "      <td>0.348660</td>\n",
       "      <td>0.585851</td>\n",
       "      <td>0.502262</td>\n",
       "      <td>0.382051</td>\n",
       "      <td>0.451512</td>\n",
       "      <td>0.512599</td>\n",
       "      <td>0.256562</td>\n",
       "      <td>0.304384</td>\n",
       "      <td>0.264407</td>\n",
       "      <td>0.398291</td>\n",
       "      <td>0.424996</td>\n",
       "      <td>0.731104</td>\n",
       "      <td>0.774302</td>\n",
       "      <td>0.798949</td>\n",
       "      <td>0.866756</td>\n",
       "      <td>0.872951</td>\n",
       "      <td>0.665148</td>\n",
       "      <td>0.778176</td>\n",
       "      <td>0.839437</td>\n",
       "      <td>0.926674</td>\n",
       "      <td>0.914078</td>\n",
       "      <td>0.672443</td>\n",
       "      <td>0.783966</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.935394</td>\n",
       "      <td>0.922332</td>\n",
       "      <td>0.640916</td>\n",
       "      <td>0.769454</td>\n",
       "      <td>0.846829</td>\n",
       "      <td>0.927806</td>\n",
       "      <td>0.901365</td>\n",
       "      <td>150.145668</td>\n",
       "      <td>3.679320e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2020</td>\n",
       "      <td>5610</td>\n",
       "      <td>56</td>\n",
       "      <td>24960.000000</td>\n",
       "      <td>0.317640</td>\n",
       "      <td>0.523649</td>\n",
       "      <td>0.571424</td>\n",
       "      <td>0.695717</td>\n",
       "      <td>0.548295</td>\n",
       "      <td>0.223621</td>\n",
       "      <td>0.161269</td>\n",
       "      <td>0.273191</td>\n",
       "      <td>0.194389</td>\n",
       "      <td>0.159884</td>\n",
       "      <td>0.121683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432434</td>\n",
       "      <td>0.369570</td>\n",
       "      <td>0.421811</td>\n",
       "      <td>0.454232</td>\n",
       "      <td>0.365132</td>\n",
       "      <td>0.638272</td>\n",
       "      <td>0.453586</td>\n",
       "      <td>0.347425</td>\n",
       "      <td>0.458562</td>\n",
       "      <td>0.373521</td>\n",
       "      <td>0.648686</td>\n",
       "      <td>0.475186</td>\n",
       "      <td>0.363064</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125267</td>\n",
       "      <td>0.095835</td>\n",
       "      <td>0.074523</td>\n",
       "      <td>0.049280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096356</td>\n",
       "      <td>0.066780</td>\n",
       "      <td>0.066763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479278</td>\n",
       "      <td>0.530173</td>\n",
       "      <td>0.579853</td>\n",
       "      <td>0.524093</td>\n",
       "      <td>0.509075</td>\n",
       "      <td>0.353067</td>\n",
       "      <td>0.351894</td>\n",
       "      <td>0.426374</td>\n",
       "      <td>0.668308</td>\n",
       "      <td>0.729662</td>\n",
       "      <td>0.494993</td>\n",
       "      <td>0.537444</td>\n",
       "      <td>0.593449</td>\n",
       "      <td>0.354150</td>\n",
       "      <td>0.514355</td>\n",
       "      <td>0.382781</td>\n",
       "      <td>0.474381</td>\n",
       "      <td>0.433060</td>\n",
       "      <td>0.756976</td>\n",
       "      <td>0.834466</td>\n",
       "      <td>0.836370</td>\n",
       "      <td>0.894612</td>\n",
       "      <td>0.856044</td>\n",
       "      <td>0.685531</td>\n",
       "      <td>0.815058</td>\n",
       "      <td>0.866490</td>\n",
       "      <td>0.946544</td>\n",
       "      <td>0.855580</td>\n",
       "      <td>0.690193</td>\n",
       "      <td>0.823684</td>\n",
       "      <td>0.873237</td>\n",
       "      <td>0.957187</td>\n",
       "      <td>0.865098</td>\n",
       "      <td>0.651691</td>\n",
       "      <td>0.766459</td>\n",
       "      <td>0.858589</td>\n",
       "      <td>0.933984</td>\n",
       "      <td>0.830317</td>\n",
       "      <td>148.087770</td>\n",
       "      <td>3.696271e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>2020</td>\n",
       "      <td>5620</td>\n",
       "      <td>56</td>\n",
       "      <td>3100.000000</td>\n",
       "      <td>0.311370</td>\n",
       "      <td>0.460542</td>\n",
       "      <td>0.469377</td>\n",
       "      <td>0.571774</td>\n",
       "      <td>0.426842</td>\n",
       "      <td>0.194885</td>\n",
       "      <td>0.137166</td>\n",
       "      <td>0.306406</td>\n",
       "      <td>0.229438</td>\n",
       "      <td>0.150951</td>\n",
       "      <td>0.076748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.542731</td>\n",
       "      <td>0.553521</td>\n",
       "      <td>0.470061</td>\n",
       "      <td>0.385331</td>\n",
       "      <td>0.303572</td>\n",
       "      <td>0.701268</td>\n",
       "      <td>0.537259</td>\n",
       "      <td>0.325219</td>\n",
       "      <td>0.387828</td>\n",
       "      <td>0.307288</td>\n",
       "      <td>0.707366</td>\n",
       "      <td>0.557657</td>\n",
       "      <td>0.338849</td>\n",
       "      <td>0.038527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142723</td>\n",
       "      <td>0.122257</td>\n",
       "      <td>0.062351</td>\n",
       "      <td>0.037659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116579</td>\n",
       "      <td>0.093238</td>\n",
       "      <td>0.062155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456468</td>\n",
       "      <td>0.494328</td>\n",
       "      <td>0.606305</td>\n",
       "      <td>0.540583</td>\n",
       "      <td>0.529711</td>\n",
       "      <td>0.365306</td>\n",
       "      <td>0.360645</td>\n",
       "      <td>0.471710</td>\n",
       "      <td>0.691933</td>\n",
       "      <td>0.739214</td>\n",
       "      <td>0.476257</td>\n",
       "      <td>0.507460</td>\n",
       "      <td>0.623351</td>\n",
       "      <td>0.362657</td>\n",
       "      <td>0.480083</td>\n",
       "      <td>0.316751</td>\n",
       "      <td>0.389683</td>\n",
       "      <td>0.396834</td>\n",
       "      <td>0.758165</td>\n",
       "      <td>0.812202</td>\n",
       "      <td>0.795196</td>\n",
       "      <td>0.843120</td>\n",
       "      <td>0.813540</td>\n",
       "      <td>0.679793</td>\n",
       "      <td>0.774875</td>\n",
       "      <td>0.805622</td>\n",
       "      <td>0.872969</td>\n",
       "      <td>0.779339</td>\n",
       "      <td>0.684940</td>\n",
       "      <td>0.783546</td>\n",
       "      <td>0.811375</td>\n",
       "      <td>0.882441</td>\n",
       "      <td>0.788669</td>\n",
       "      <td>0.640828</td>\n",
       "      <td>0.721507</td>\n",
       "      <td>0.798732</td>\n",
       "      <td>0.862810</td>\n",
       "      <td>0.747614</td>\n",
       "      <td>147.080521</td>\n",
       "      <td>4.559496e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2020</td>\n",
       "      <td>5650</td>\n",
       "      <td>56</td>\n",
       "      <td>66857.142857</td>\n",
       "      <td>0.373556</td>\n",
       "      <td>0.563425</td>\n",
       "      <td>0.681905</td>\n",
       "      <td>0.628636</td>\n",
       "      <td>0.622690</td>\n",
       "      <td>0.208741</td>\n",
       "      <td>0.028904</td>\n",
       "      <td>0.129663</td>\n",
       "      <td>0.113519</td>\n",
       "      <td>0.140756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263546</td>\n",
       "      <td>0.083477</td>\n",
       "      <td>0.167074</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.041807</td>\n",
       "      <td>0.288119</td>\n",
       "      <td>0.241923</td>\n",
       "      <td>0.314448</td>\n",
       "      <td>0.413491</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>0.301222</td>\n",
       "      <td>0.254244</td>\n",
       "      <td>0.328257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078888</td>\n",
       "      <td>0.008504</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058522</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.025080</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538570</td>\n",
       "      <td>0.672737</td>\n",
       "      <td>0.630218</td>\n",
       "      <td>0.562630</td>\n",
       "      <td>0.524402</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.455930</td>\n",
       "      <td>0.431993</td>\n",
       "      <td>0.759637</td>\n",
       "      <td>0.758660</td>\n",
       "      <td>0.546210</td>\n",
       "      <td>0.678653</td>\n",
       "      <td>0.638948</td>\n",
       "      <td>0.456299</td>\n",
       "      <td>0.544200</td>\n",
       "      <td>0.455668</td>\n",
       "      <td>0.532990</td>\n",
       "      <td>0.504359</td>\n",
       "      <td>0.778173</td>\n",
       "      <td>0.878784</td>\n",
       "      <td>0.895730</td>\n",
       "      <td>0.896090</td>\n",
       "      <td>0.884397</td>\n",
       "      <td>0.701122</td>\n",
       "      <td>0.856502</td>\n",
       "      <td>0.935415</td>\n",
       "      <td>0.901240</td>\n",
       "      <td>0.895208</td>\n",
       "      <td>0.706999</td>\n",
       "      <td>0.868937</td>\n",
       "      <td>0.946862</td>\n",
       "      <td>0.913040</td>\n",
       "      <td>0.906227</td>\n",
       "      <td>0.660738</td>\n",
       "      <td>0.790746</td>\n",
       "      <td>0.918526</td>\n",
       "      <td>0.862593</td>\n",
       "      <td>0.863937</td>\n",
       "      <td>149.171024</td>\n",
       "      <td>9.973148e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  FIPS State_code  ...      tmin    ELN_pred Total_yield_pred\n",
       "Mn                          ...         8                             \n",
       "0    2020   110          1  ...  1.051956  149.404142     2.042355e+07\n",
       "1    2020   120          1  ...  1.051016  149.379494     8.012716e+06\n",
       "2    2020   130          1  ...  0.964909  151.725168     3.120987e+06\n",
       "3    2020   140          1  ...  0.930841  151.492804     4.129694e+06\n",
       "4    2020   150          1  ...  0.924183  151.391842     2.690233e+06\n",
       "..    ...   ...        ...  ...       ...         ...              ...\n",
       "257  2020  5580         55  ...  0.912529  150.883983     1.248716e+08\n",
       "258  2020  5590         55  ...  0.901365  150.145668     3.679320e+07\n",
       "259  2020  5610         56  ...  0.830317  148.087770     3.696271e+06\n",
       "260  2020  5620         56  ...  0.747614  147.080521     4.559496e+05\n",
       "261  2020  5650         56  ...  0.863937  149.171024     9.973148e+06\n",
       "\n",
       "[262 rows x 96 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_gs = pd.merge(weather_predict, fips_area, on = 'FIPS')\n",
    "\n",
    "df_pred_ELN = df_pred_gs.pivot_table(index=['Year','FIPS','State_code', 'Area'], columns=['Mn']).reset_index()\n",
    "df_pred_ELN['ELN_pred'] = rescale_back(elasticnet.predict(df_pred_ELN.iloc[:, 4:]), df_ELN['Yield'].values)\n",
    "df_pred_ELN['Total_yield_pred'] = df_pred_ELN['ELN_pred'] * df_pred_ELN['Area']\n",
    "df_pred_ELN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1XMw16OLirwE"
   },
   "source": [
    "<a id='section3'></a>\n",
    "## 2020 National Corn Yield Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QzQbLRO0iEbZ",
    "outputId": "78586445-dbd9-4a43-f7e9-bf0cc63b24c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction for 2020 corn yield is 151.2106689823216\n"
     ]
    }
   ],
   "source": [
    "print(f\"The prediction for 2020 corn yield is {df_pred_ELN['Total_yield_pred'].sum() / df_pred_ELN['Area'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HMozGXzqX6g1"
   },
   "outputs": [],
   "source": [
    "# save data for the final prediction\n",
    "weather_pred.to_csv('data/weather_2020.csv', index=False)\n",
    "\n",
    "# save both model\n",
    "model.save('rnn_weather_lstm.h5')\n",
    "\n",
    "import pickle\n",
    "pickle.dump(elasticnet, open('eln_yield.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cN6rpFqfcuna"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code_challenge_modeling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
